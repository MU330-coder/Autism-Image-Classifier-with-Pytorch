{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-15T17:03:40.777580Z","iopub.execute_input":"2022-08-15T17:03:40.778281Z","iopub.status.idle":"2022-08-15T17:03:41.010525Z","shell.execute_reply.started":"2022-08-15T17:03:40.778242Z","shell.execute_reply":"2022-08-15T17:03:41.009527Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data import RandomSampler\n\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\n#from torchvision.datasets import ImageFolder\n\nfrom matplotlib import pyplot as plt\n\n\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:41.013982Z","iopub.execute_input":"2022-08-15T17:03:41.015994Z","iopub.status.idle":"2022-08-15T17:03:43.124086Z","shell.execute_reply.started":"2022-08-15T17:03:41.015964Z","shell.execute_reply":"2022-08-15T17:03:43.123107Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"DIR_TRAIN = \"../input/autism-image-data/AutismDataset/train/\"\n\nDIR_TEST = \"../input/autism-image-data/AutismDataset/test/\"","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.126695Z","iopub.execute_input":"2022-08-15T17:03:43.127258Z","iopub.status.idle":"2022-08-15T17:03:43.131876Z","shell.execute_reply.started":"2022-08-15T17:03:43.127220Z","shell.execute_reply":"2022-08-15T17:03:43.130766Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_imgs = []\nvalid_imgs = []\ntest_imgs = []\n\n    \nfor img in os.listdir(DIR_TRAIN):\n    train_imgs.append(DIR_TRAIN + img)\n    \nfor img in os.listdir(DIR_TEST):\n    test_imgs.append(DIR_TEST + img)\n\nfile = (train_imgs[0])\n\ndataSetImgs = train_imgs+test_imgs\ndataSetLen = len(dataSetImgs)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.133418Z","iopub.execute_input":"2022-08-15T17:03:43.134521Z","iopub.status.idle":"2022-08-15T17:03:43.144420Z","shell.execute_reply.started":"2022-08-15T17:03:43.134485Z","shell.execute_reply":"2022-08-15T17:03:43.143392Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimg = mpimg.imread(train_imgs[0])\nimgplot = plt.imshow(img)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.145533Z","iopub.execute_input":"2022-08-15T17:03:43.145801Z","iopub.status.idle":"2022-08-15T17:03:43.405873Z","shell.execute_reply.started":"2022-08-15T17:03:43.145767Z","shell.execute_reply":"2022-08-15T17:03:43.404561Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(\"the shape of the images is\",img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.407331Z","iopub.execute_input":"2022-08-15T17:03:43.408791Z","iopub.status.idle":"2022-08-15T17:03:43.417508Z","shell.execute_reply.started":"2022-08-15T17:03:43.408752Z","shell.execute_reply":"2022-08-15T17:03:43.415752Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# class for the data","metadata":{}},{"cell_type":"code","source":"class AutismData(Dataset):\n    \n    def __init__(self, imgs_list, transforms = None):\n        \n        super().__init__()\n        self.imgs_list = imgs_list\n        #self.class_to_int = class_to_int\n        self.transforms = transforms\n        \n        \n    def __getitem__(self, index):\n    \n        image_path = self.imgs_list[index]\n        \n        #Reading image\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        \n        #Retriving class label\n        \n        # labels\n        label = self.imgs_list[index].split('/',5)[-1].split('.')[0]\n\n        #Applying transforms on image\n        if self.transforms:\n            image = self.transforms(image)\n            \n            \n        if label == 'Autistic':\n            label = 0\n        \n        else :\n            label = 1\n        \n        return image, label\n    def __len__(self):\n        return len(self.imgs_list)\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.426250Z","iopub.execute_input":"2022-08-15T17:03:43.426946Z","iopub.status.idle":"2022-08-15T17:03:43.442257Z","shell.execute_reply.started":"2022-08-15T17:03:43.426903Z","shell.execute_reply":"2022-08-15T17:03:43.441238Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_class = AutismData(train_imgs)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.444044Z","iopub.execute_input":"2022-08-15T17:03:43.445793Z","iopub.status.idle":"2022-08-15T17:03:43.453098Z","shell.execute_reply.started":"2022-08-15T17:03:43.445743Z","shell.execute_reply":"2022-08-15T17:03:43.452061Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_mean_and_std(loader):\n    mean = 0\n    std = 0\n    total_images_count  = 0\n    for images , _ in loader:\n        images_count_in_a_batch  = images.size(0)\n        images = images.view(images_count_in_a_batch,images.size(1),-1)\n        mean += images.mean(2).sum(0)\n        std += images.std(2).sum(0)\n        total_images_count += images_count_in_a_batch\n        \n    mean /= total_images_count\n    sdd /= total_images_count\n    return mean, std\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.463414Z","iopub.execute_input":"2022-08-15T17:03:43.464139Z","iopub.status.idle":"2022-08-15T17:03:43.474118Z","shell.execute_reply.started":"2022-08-15T17:03:43.464102Z","shell.execute_reply":"2022-08-15T17:03:43.472697Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Transform Variables","metadata":{}},{"cell_type":"code","source":"def get_mean_std(loader):\n    channels_s, channels_sqr,num_batches = 0,0,0\n    for data, _ in loader:\n        channels_s += torch.mean(data,dim=[0,2,3])\n        channels_sqr += torch.mean(data**2,dim=[0,2,3])\n        num_batches += 1\n        \n        mean = channels_s/num_batches\n        std = (channels_sqr/num_batches - mean**2)**0.5\n        \n        return mean, std","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.477297Z","iopub.execute_input":"2022-08-15T17:03:43.477602Z","iopub.status.idle":"2022-08-15T17:03:43.486059Z","shell.execute_reply.started":"2022-08-15T17:03:43.477578Z","shell.execute_reply":"2022-08-15T17:03:43.485149Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Create the Train and Test Objects","metadata":{}},{"cell_type":"code","source":"data_set_img = AutismData(imgs_list=dataSetImgs,transforms=T.Compose([T.ToTensor(),T.Resize((224,224)),\n                                                                  T.RandomRotation(10),  \n                                                                #T.Normalize(mean,std)\n                                                            ]))\n\n#test_set = AutismData(imgs_list=test_imgs,transforms=T.Compose([T.ToTensor(),T.Resize((224,224))])) # TODO CREATE THE TRANSFORM FUNCTION","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.489524Z","iopub.execute_input":"2022-08-15T17:03:43.489769Z","iopub.status.idle":"2022-08-15T17:03:43.494906Z","shell.execute_reply.started":"2022-08-15T17:03:43.489746Z","shell.execute_reply":"2022-08-15T17:03:43.493873Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Dummy DataLoaders\n","metadata":{}},{"cell_type":"code","source":"dummy_train_loader = DataLoader(dataset=data_set_img,batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.496947Z","iopub.execute_input":"2022-08-15T17:03:43.497826Z","iopub.status.idle":"2022-08-15T17:03:43.505065Z","shell.execute_reply.started":"2022-08-15T17:03:43.497791Z","shell.execute_reply":"2022-08-15T17:03:43.503948Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"mean, std = get_mean_std(dummy_train_loader)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:43.506876Z","iopub.execute_input":"2022-08-15T17:03:43.507228Z","iopub.status.idle":"2022-08-15T17:03:44.140153Z","shell.execute_reply.started":"2022-08-15T17:03:43.507191Z","shell.execute_reply":"2022-08-15T17:03:44.138468Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(mean)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:44.142017Z","iopub.execute_input":"2022-08-15T17:03:44.142644Z","iopub.status.idle":"2022-08-15T17:03:44.155858Z","shell.execute_reply.started":"2022-08-15T17:03:44.142608Z","shell.execute_reply":"2022-08-15T17:03:44.153517Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Data Class with Transform","metadata":{}},{"cell_type":"code","source":"data_set_img = AutismData(imgs_list=dataSetImgs,transforms=T.Compose([T.ToTensor(),T.Resize((224,224)),\n                                                                  T.RandomRotation(10),  \n                                                                #T.Normalize(mean,std)\n                                                            ]))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:44.157332Z","iopub.execute_input":"2022-08-15T17:03:44.158118Z","iopub.status.idle":"2022-08-15T17:03:44.167948Z","shell.execute_reply.started":"2022-08-15T17:03:44.158078Z","shell.execute_reply":"2022-08-15T17:03:44.166288Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(dataSetLen)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:44.170115Z","iopub.execute_input":"2022-08-15T17:03:44.170845Z","iopub.status.idle":"2022-08-15T17:03:44.178932Z","shell.execute_reply.started":"2022-08-15T17:03:44.170809Z","shell.execute_reply":"2022-08-15T17:03:44.177242Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Splitting the Data","metadata":{}},{"cell_type":"code","source":"train_len ,test_len = dataSetLen - 1420, 1420\n\n\ntrain_set , test_set = torch.utils.data.random_split(data_set_img,[train_len,test_len])\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:44.180892Z","iopub.execute_input":"2022-08-15T17:03:44.181235Z","iopub.status.idle":"2022-08-15T17:03:44.189723Z","shell.execute_reply.started":"2022-08-15T17:03:44.181202Z","shell.execute_reply":"2022-08-15T17:03:44.187879Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Data Loaders","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=32,shuffle=True)\n\ntest_loader = DataLoader(test_set, batch_size=32,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:44.191403Z","iopub.execute_input":"2022-08-15T17:03:44.192099Z","iopub.status.idle":"2022-08-15T17:03:44.199886Z","shell.execute_reply.started":"2022-08-15T17:03:44.192064Z","shell.execute_reply":"2022-08-15T17:03:44.197779Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Create Model Class","metadata":{}},{"cell_type":"code","source":"from torch.nn.modules.container import Sequential\nimport torch.nn as nn\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        # first conv layers\n        self.network  = nn.Sequential( \n\n            # TODO: make it with 6 conv layers along   with relu and max_p and use batchnorm2d\n            # and three linear layers on the end and do a flatten before pass to linear layers\n\n            #  first layer\n            nn.Conv2d(3, 30, 3,padding=1,stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.BatchNorm2d(30),\n\n            # second layer\n            nn.Conv2d(30, 28, 3,padding=1,stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2) ,\n            nn.BatchNorm2d(28),\n\n\n            # third layer\n            nn.Conv2d(28, 70, 3,padding=1,stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2) ,\n            nn.BatchNorm2d(70),\n\n            # fourth layer\n            nn.Conv2d(70,16, 3,padding=1,stride=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.BatchNorm2d(16),\n\n        # flatten goes here: \n            nn.Flatten(),\n\n            # fifth layer \n            nn.Linear(3136,50),\n            nn.Linear(50, 2),\n            nn.Softmax(dim=1)\n        \n            )\n    \n    # it's the forward function that defines the network structure\n    # we're accepting only a single input in here, but if you want,\n    # feel free to use more\n    def forward(self, x):\n\n        x = self.network(x)\n\n        # in your model definition you can go full crazy and use arbitrary\n        # python code to define your model structure\n        # all these are perfectly legal, and will be handled correctly\n        # by autograd:\n        # if x.gt(0) > x.numel() / 2:\n        #      ...\n        #\n        # you can even do a loop and reuse the same module inside it\n        # modules no longer hold ephemeral state, so you can use them\n        # multiple times during your forward pass\n        # while x.norm(2) < 10:\n        #    x = self.conv1(x)\n\n        return x\n\nmodel = Net()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:44.201626Z","iopub.execute_input":"2022-08-15T17:03:44.201973Z","iopub.status.idle":"2022-08-15T17:03:44.237327Z","shell.execute_reply.started":"2022-08-15T17:03:44.201940Z","shell.execute_reply":"2022-08-15T17:03:44.235994Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    model = model.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:44.238827Z","iopub.execute_input":"2022-08-15T17:03:44.239442Z","iopub.status.idle":"2022-08-15T17:03:46.772234Z","shell.execute_reply.started":"2022-08-15T17:03:44.239398Z","shell.execute_reply":"2022-08-15T17:03:46.771242Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.SGD(model.parameters(), lr=0.003,momentum=0.9)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:46.773896Z","iopub.execute_input":"2022-08-15T17:03:46.774288Z","iopub.status.idle":"2022-08-15T17:03:46.779919Z","shell.execute_reply.started":"2022-08-15T17:03:46.774251Z","shell.execute_reply":"2022-08-15T17:03:46.778787Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"epochs = 10\ntrain_loss, val_loss = [], []\naccuracy_total_train, accuracy_total_val = [], []\n\nfor epoch in range(epochs):\n   \n    total_train_loss = 0\n    total_val_loss = 0\n\n    model.train()\n    \n    total = 0\n    # training our model\n    for idx, (image, label) in enumerate(train_loader):\n        image, label = image.to(device), label.to(device)\n\n        optimizer.zero_grad()\n\n        pred = model(image)\n\n        loss = criterion(pred, label)\n        total_train_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n\n        pred = torch.nn.functional.softmax(pred, dim=1)\n        for i, p in enumerate(pred):\n            if label[i] == torch.max(p.data, 0)[1]:\n                total = total + 1\n                \n    accuracy_train = total / len(train_set)\n    accuracy_total_train.append(accuracy_train)\n\n    total_train_loss = total_train_loss / (idx + 1)\n    train_loss.append(total_train_loss)\n    \n    # validating our model\n    model.eval()\n    total = 0\n    for idx, (image, label) in enumerate(test_loader):\n        image, label = image.cuda(), label.cuda()\n        pred = model(image)\n        loss = criterion(pred, label)\n        total_val_loss += loss.item()\n\n        pred = torch.nn.functional.softmax(pred, dim=1)\n        for i, p in enumerate(pred):\n            if label[i] == torch.max(p.data, 0)[1]:\n                total = total + 1\n\n    accuracy_val = total / len(test_set)\n    accuracy_total_val.append(accuracy_val)\n\n    total_val_loss = total_val_loss / (idx + 1)\n    val_loss.append(total_val_loss)\n\n   \n    print(\"Epoch: {}/{}  \".format(epoch, epochs),\n            \"Training loss: {:.4f}  \".format(total_train_loss),\n            \"Testing loss: {:.4f}  \".format(total_val_loss),\n            \"Train accuracy: {:.4f}  \".format(accuracy_train),\n            \"Test accuracy: {:.4f}  \".format(accuracy_val))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-15T17:03:46.781832Z","iopub.execute_input":"2022-08-15T17:03:46.782237Z","iopub.status.idle":"2022-08-15T17:07:50.468938Z","shell.execute_reply.started":"2022-08-15T17:03:46.782202Z","shell.execute_reply":"2022-08-15T17:07:50.467891Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}